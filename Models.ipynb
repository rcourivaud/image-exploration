{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libprotoc 3.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!protoc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.ImageFolder(\"../data/dataset/train/\", transform = transformations )\n",
    "valid_set = datasets.ImageFolder(\"../data/dataset/valid/\", transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "model = models.densenet161(pretrained=True)\n",
    "# Turn off training for their parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, in_feature_number, class_number):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "\n",
    "        self.f1 = nn.Linear(in_feature_number, 1024)\n",
    "        self.f2 = nn.Linear(1024, 512)\n",
    "        self.f3 = nn.Linear(512, num_labels)\n",
    "        self.soft_max = nn.LogSoftmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.f2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.f3(x)\n",
    "        output = self.soft_max(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace default classifier with new classifier\n",
    "classifier_ = LinearClassifier(in_feature_number=model.classifier.in_features, class_number=num_labels)\n",
    "model.classifier = classifier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Move model to the device specified above\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "# Set the optimizer function using torch.optim as optim library\n",
    "optimizer = optim.Adam(model.classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CHECKPOINT = \"./models/check_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'serialized_options'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-01c1c42b6efe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtorchvis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchVis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/torchvis.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvisdom_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisdomWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_sprite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_tsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_pbtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevent_file_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventFileWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0monnx_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpytorch_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/event_file_writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/proto/event_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboardX_dot_proto_dot_summary__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/proto/summary_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboardX_dot_proto_dot_tensor__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/proto/tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboardX_dot_proto_dot_resource__handle__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboardX_dot_proto_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboardX_dot_proto_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/proto/resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0msyntax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'proto3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mserialized_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\030org.tensorflow.frameworkB\\016ResourceHandleP\\001\\370\\001\\001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mserialized_pb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n(tensorboardX/proto/resource_handle.proto\\x12\\x0ctensorboardX\\\"r\\n\\x13ResourceHandleProto\\x12\\x0e\\n\\x06\\x64\\x65vice\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\tcontainer\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x11\\n\\thash_code\\x18\\x04 \\x01(\\x04\\x12\\x17\\n\\x0fmaybe_type_name\\x18\\x05 \\x01(\\tB/\\n\\x18org.tensorflow.frameworkB\\x0eResourceHandleP\\x01\\xf8\\x01\\x01\\x62\\x06proto3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'serialized_options'"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> TRAINING EPOCH 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999d054daf484c6c9b65d4493bbf22e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17519), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EVALUATING EPOCH 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b8913261bf44fd850199a1c20688fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.865875\n",
      "Epoch: 0 \tTraining Loss: 0.483130 \tValidation Loss: 0.371526\n",
      " -> TRAINING EPOCH 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aeb3c2aaad482e839cf99be504cee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17519), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EVALUATING EPOCH 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12736ac4102843f29ed1cd704c7352ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "num_of_examples = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # Training the model\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    print(f\" -> TRAINING EPOCH {epoch}\")\n",
    "    for inputs, labels in tqdm_notebook(train_loader):\n",
    "        # Move to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Clear optimizers\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model.forward(inputs)\n",
    "        # Loss\n",
    "        loss = criterion(output, labels)\n",
    "        # Calculate gradients (backpropogation)\n",
    "        loss.backward()\n",
    "        # Adjust parameters based on gradients\n",
    "        optimizer.step()\n",
    "        # Add the loss to the training set's rnning loss\n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "        \n",
    "        # Print the progress of our training\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "        if counter >= num_of_examples:\n",
    "            break\n",
    "    \n",
    "        \n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    # Tell torch not to calculate gradients\n",
    "    \n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, PATH_CHECKPOINT + str(epoch) + \".pt\")\n",
    "    \n",
    "    print(f\"-> EVALUATING EPOCH {epoch}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm_notebook(valid_loader):\n",
    "            # Move to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "            output = model.forward(inputs)\n",
    "            # Calculate Loss\n",
    "            valloss = criterion(output, labels)\n",
    "            # Add loss to the validation set's running loss\n",
    "            val_loss += valloss.item()*inputs.size(0)\n",
    "            \n",
    "            # Since our model outputs a LogSoftmax, find the real \n",
    "            # percentages by reversing the log function\n",
    "            output = torch.exp(output)\n",
    "            # Get the top class of the output\n",
    "            top_p, top_class = output.topk(1, dim=1)\n",
    "            # See how many of the classes were correct?\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            # Calculate the mean (get the accuracy for this batch)\n",
    "            # and add it to the running accuracy for this epoch\n",
    "            accuracy += torch.sum(equals.type(torch.FloatTensor)).item()\n",
    "            \n",
    "            # Print the progress of our evaluation\n",
    "            counter += 1\n",
    "            if counter >= num_of_examples:\n",
    "                break\n",
    "            \n",
    "    # Get the average loss for the entire epoch\n",
    "    train_loss = train_loss/(train_loader.batch_size*(counter))\n",
    "    valid_loss = val_loss/(valid_loader.batch_size*(counter))\n",
    "    # Print out the information\n",
    "    print('Accuracy: ', accuracy/(valid_loader.batch_size*counter))\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in valid_loader:\n",
    "    print(image)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type LinearClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./model.pt\"\n",
    "\n",
    "torch.save(model, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.89071875\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy/(valid_loader.batch_size*counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
